#!/usr/bin/env python3

"""
Class to read q-g data set, do jet finding, and compute subjet basis
"""

import os
import sys
import argparse
import yaml
import h5py
import time
from collections import defaultdict
import math
import csv
import statistics

# Data analysis and plotting
import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
import seaborn as sns
import uproot

# Fastjet via python (from external library heppy)
import fastjet as fj
import fjcontrib
import fjext

# Energy flow package
import energyflow

# Base class
sys.path.append('.')
from base import common_base

################################################################
class ProcessQG(common_base.CommonBase):

    #---------------------------------------------------------------
    # Constructor
    #---------------------------------------------------------------
    def __init__(self, config_file='', output_dir='', **kwargs):
        super(common_base.CommonBase, self).__init__(**kwargs)
       
        self.start_time = time.time()
        
        self.config_file = config_file
        self.output_dir = output_dir
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)
        
        # Initialize config file
        self.initialize_config()

        # Initialize data structures to store results
        self.initialize_data_structures()

        # Load dataset (quark-gluon or Z/QCD)
        self.load_dataset()
     
        #print(self)
        print()

    #---------------------------------------------------------------
    # Initialize config file into class members
    #---------------------------------------------------------------
    def initialize_config(self):
    
        # Read config file
        with open(self.config_file, 'r') as stream:
          config = yaml.safe_load(stream)
        
        #Which Classification task
        self.dataset_type = config['dataset_type']
        
        self.R = config['R']
        self.pt = config['pt']
        self.y_max = config['y_max']
        self.n_total = config['n_total']
        self.n_val = config['n_val']
        self.n_test = config['n_test']
        self.event_index = 0
        
        # If QCD vs. Zjet case, load the files generated by Mateusz
        if self.dataset_type == 'Zjet':
            # Jet mass cut
            self.mj_min = config['mj_min']
            self.mj_max = config['mj_max']


        # Nsubjettiness basis
        self.K = config['K_max']
        self.N_list = []
        self.beta_list = []

        for i in range(self.K-2):
            self.N_list += [i+1] * 3
            self.beta_list += [0.5,1,2]
            print()
        self.N_list += [self.K-1] * 2  
        self.beta_list += [1,2]

        print()
        print(f'N list: {self.N_list}')
        print(f'beta list: {self.beta_list}')
        print()
        

        # Subjet basis
        self.subjet_basis = config['subjet_basis']
        self.njet_list = config['njet']
        self.N_max_list= config['N_max']
        self.r_list = config['r']

        if type(self.njet_list) != list:
            print(f'ERROR: njet must be a list')
            print(f'Changing njet into a list')
            self.njet_list = list([self.njet_list])
        if type(self.N_max_list) != list:
            print(f'ERROR: N_max must be a list')
            print(f'Changing N_max into a list')
            self.N_max_list = list([self.N_max_list])


        # Clustering Algorithm 
        self.Clustering_Alg = config['Clustering_Alg']


        if self.subjet_basis == 'exclusive':
            if self.r_list != [self.R]:
                    print(f'ERROR: Wrong subjet radius r. For exlusive basis we need r = {self.R}')
                    print(f'Changing radius to r = {self.R}')
                    self.r_list = [self.R]
                    time.sleep(2)
            if self.Clustering_Alg == 'antikt_algorithm':
                sys.exit(f'ERROR: For the exclusive algorithm we can not use antikt_algorithm (fastjet throws a warning)')
                


        # Laman Construction
        self.laman_load = config['laman']
        self.Laman_construction = config['Laman_construction']


        # Load Herwig Dataset:
        self.Herwig_dataset = config['Herwig_dataset']    


    #---------------------------------------------------------------        
    # Initialize empty data structures to store results
    #---------------------------------------------------------------
    def initialize_data_structures(self):

        # Create two-layer nested defaultdict of lists to store jet observables
        self.output = defaultdict(lambda: defaultdict(list))

    #---------------------------------------------------------------
    # Load qg data set 
    #---------------------------------------------------------------
    def load_dataset(self):
        
        # qvsg Classification problem
        
        if self.dataset_type == 'qg':
            
            if self.pt[0] == 500 and self.pt[1] == 550:    # Jesse's Dataset 
                # https://energyflow.network/docs/datasets/#quark-and-gluon-jets
                # X : a three-dimensional numpy array of jets:
                #     list of jets with list of particles for each jet, with (pt,y,phi,pid) values for each particle
                # y : a numpy array of quark/gluon jet labels (quark=1 and gluon=0).
                # The jets are padded with zero-particles in order to make a contiguous array.
                print()
                print('Loading qg dataset:')
                X, self.y = energyflow.datasets.qg_jets.load(num_data=self.n_total, pad=True, 
                                                            generator='pythia',  # Herwig is also available
                                                            with_bc=False        # Turn on to enable heavy quarks
                                                            )
                print('(n_jets, n_particles per jet, n_variables): {}'.format(X.shape))
                print()

                # Next, we will transform these into fastjet::PseudoJet objects.
                # This allows us to use the fastjet contrib to compute our custom basis (Nsubjettiness, subjets, etc).

                # Translate 3D numpy array (100,000 x 556 particles x 4 vars) into a dataframe
                # Define a unique index for each jet
                columns = ['pt', 'y', 'phi', 'pid']
                df_particles = pd.DataFrame(X.reshape(-1, 4), columns=columns)
                df_particles.index = np.repeat(np.arange(X.shape[0]), X.shape[1]) + 1
                df_particles.index.name = 'jet_id'
                
                # (i) Group the particle dataframe by jet id
                #     df_particles_grouped is a DataFrameGroupBy object with one particle dataframe per jet
                df_fjparticles_grouped = df_particles.groupby('jet_id')
                

                # (ii) Transform the DataFrameGroupBy object to a SeriesGroupBy of fastjet::PseudoJets
                # NOTE: for now we neglect the mass -- and assume y=eta
                # TO DO: Add y to https://github.com/matplo/heppy/blob/master/cpptools/src/fjext/fjtools.cxx
                # TO DO: Add mass vector using pdg
                print('Converting particle dataframe to fastjet::PseudoJets...')
                self.df_fjparticles = df_fjparticles_grouped.apply(self.get_fjparticles)
                print('Done.')
                print()

                # Mass cut
                self.mj_min=0
                self.mj_max=180
                

                jet_mass_cut_list = []
                for iterator,jet in enumerate(self.df_fjparticles):
                    jet_def = fj.JetDefinition(fj.antikt_algorithm, fj.JetDefinition.max_allowable_R)
                    cs = fj.ClusterSequence(jet, jet_def)
                    jet_selected = fj.sorted_by_pt(cs.inclusive_jets())[0]
                    jet_mass = jet_selected.m()
                    if jet_mass >= self.mj_min  and jet_mass <= self.mj_max:
                        jet_mass_cut_list.append(iterator)


                print(f'For the q vs g, {math.trunc(100*(1-len(jet_mass_cut_list)/len(self.df_fjparticles)))}% jets are outside the mass range ({self.mj_min}-{self.mj_max} GeV)') 

                # Load the Herwig Dataset for testing (For now only pfn and sub_pfn are supported)
                if self.Herwig_dataset == 'True':

                    X_herwig, self.y_herwig = energyflow.datasets.qg_jets.load(num_data=self.n_val + self.n_test, pad=True, 
                                                            generator='herwig',  # Herwig is also available
                                                            with_bc=False        # Turn on to enable heavy quarks
                                                            )
                
                    columns = ['pt', 'y', 'phi', 'pid']
                    df_particles_herwig = pd.DataFrame(X_herwig.reshape(-1, 4), columns=columns)
                    df_particles_herwig.index = np.repeat(np.arange(X_herwig.shape[0]), X_herwig.shape[1]) + 1
                    df_particles_herwig.index.name = 'jet_id'

                    df_fjparticles_herwig_grouped = df_particles_herwig.groupby('jet_id')

                    self.df_fjparticles_herwig = df_fjparticles_herwig_grouped.apply(self.get_fjparticles)
            elif self.pt[0] == 300 or self.pt[0] == 500 or self.pt[0] == 1000 :
                if self.pt[0] == 300 and self.pt[1] == 350:
                    
                    if self.Herwig_dataset == 'True': 
                        sys.exit("ERR0R: There is not a Herwig dataset for the given pt range")
                        print()
                        
                    input_files = []
                    with open("/rstorage/ml/pythia/quark_rootified_300_350/file_list.txt","r") as csvfile:
                        reader = csv.reader(csvfile)
                        for row in reader:
                            input_files += row
                        
                    with open("/rstorage/ml/pythia/gluon_rootified_300_350/file_list.txt","r") as csvfile:
                        reader = csv.reader(csvfile)
                        for row in reader:
                            input_files += row

                if self.pt[0] == 500 and self.pt[1] == 650: # If you want to load Mateusz's and not Jesse's. Currently self.pt[1] == 650 in order to load Jesse's dataset
                    
                    if self.Herwig_dataset == 'True': 
                        sys.exit("ERR0R: There is not a Herwig dataset for the given pt range")
                        print()
                        
                    input_files = []
                    with open("/rstorage/ml/pythia/quark_rootified/file_list.txt","r") as csvfile:
                        reader = csv.reader(csvfile)
                        for row in reader:
                            input_files += row
                        
                    with open("/rstorage/ml/pythia/gluon_rootified/file_list.txt","r") as csvfile:
                        reader = csv.reader(csvfile)
                        for row in reader:
                            input_files += row

                if self.pt[0] == 1000 and self.pt[1] == 1050:
                    
                    if self.Herwig_dataset == 'True': 
                        sys.exit("ERR0R: There is not a Herwig dataset for the given pt range")
                        print()

                    input_files = []                
                    with open("/rstorage/ml/pythia/quark_rootified_1000_1050/file_list.txt","r") as csvfile:
                        reader = csv.reader(csvfile)
                        for row in reader:
                            input_files += row
                    
                    with open("/rstorage/ml/pythia/gluon_rootified_1000_1050/file_list.txt","r") as csvfile:
                        reader = csv.reader(csvfile)
                        for row in reader:
                            input_files += row

                tree_name = 'tree_Particle_gen' # Right now we are only considering ungroomed jets
                unique_identifier =  ['run_number', 'ev_id']
                tree_columns = unique_identifier + ['ParticlePt', 'ParticleEta', 'ParticlePhi', 'ParticlePID']

                print('Convert ROOT trees to pandas dataframes...')
                print(f'    track_tree_name = {tree_name}')

                # The event numbers are only guaranteed to be consistent within a given file,
                # so we perform the groupby for each file before merging them together
                self.df_fjparticles = None
                self.y = None
                n_jets = 0
                n_jets_quark, n_jets_gluon = 0, 0
            
                quark_jet_filepattern= "pythia_quark"
                gluon_jet_filepattern = "pythia_gluon"

                for i,input_file in enumerate(input_files):
                    if (quark_jet_filepattern in input_file and n_jets_quark < self.n_total/2.) or (gluon_jet_filepattern in input_file and n_jets_gluon < self.n_total/2.):
                        
                        print(f'Loading file {i} / {len(input_files)}... ({input_file})')

                        if quark_jet_filepattern in input_file:
                            q_or_g = 'q'
                        elif gluon_jet_filepattern in input_file:
                            q_or_g = 'g'

                        
                        jet_tree = None
                        jet_df = None
                        with uproot.open(input_file)[tree_name] as jet_tree:
                            if not jet_tree:
                                raise ValueError(f'Tree {tree_name} not found in file {input_file}')
                            jet_df = uproot.concatenate(jet_tree, tree_columns, library='pd')
                            
                        jet_df['ParticleM'] = energyflow.pids2ms(jet_df['ParticlePID'], error_on_unknown=True)

                        jet_df.rename(columns={'ParticlePt': 'pt', 'ParticleEta': 'y', 'ParticlePhi': 'phi', 'ParticlePID': 'pid', 'ParticleM': 'm'}, inplace=True) #Mateusz's dataset requires ParticleM, Jesse's does not have this info
                        jet_df = jet_df.drop('pid', axis=1)

                        
                        # (i) Group the particle dataframe by jet
                        #     jet_df_grouped is a DataFrameGroupBy object with one particle dataframe per jet
                        jet_df_grouped = jet_df.groupby(unique_identifier)
                        
                        # (ii) Transform the DataFrameGroupBy object to a SeriesGroupBy of fastjet particles
                        df_fjparticles = jet_df_grouped.apply(self.get_fjparticles)


                        # Check if the kinematic cuts are satisfied           
                    
                        jet_pt_list, jet_eta_list = [], []

                        for iterator, jet in enumerate(df_fjparticles):
                            
                            jet_def = fj.JetDefinition(fj.antikt_algorithm, fj.JetDefinition.max_allowable_R)
                            cs = fj.ClusterSequence(jet, jet_def)
                            jet_selected = fj.sorted_by_pt(cs.inclusive_jets())[0]

                            jet_pt = jet_selected.pt()
                            jet_pt_list.append(jet_pt)

                            jet_eta = abs(jet_selected.eta())
                            jet_eta_list.append(jet_eta)
                            
                        pt_cut_list, eta_cut_list = [], []
                        
                        for iterator, jet_pt in enumerate(jet_pt_list):
                            if self.pt[0] <= jet_pt <= self.pt[1]:  pt_cut_list.append(iterator)
                            if jet_eta_list[iterator] <= 1.7:       eta_cut_list.append(iterator)


                        cut_list = list(set(pt_cut_list) & set(eta_cut_list)) # The jets that satisfy both the eta and the pt cuts
                        
                        print(f'For file {i}, that contains the {q_or_g} Pythia dataset, {math.trunc(100*(1-len(pt_cut_list)/len(df_fjparticles)))}% jets are outside the pt range: {self.pt[0],self.pt[1]}')                    
                        print(f'For file {i}, that contains the {q_or_g} Pythia dataset, {math.trunc(100*(1-len(eta_cut_list)/len(df_fjparticles)))}% jets are outside the eta range: eta <= 1.7') 
                        print()

                        #if len(jet_pt_list) != len(set(jet_pt_list)): # The pt's have ~15 digits accuracy, so if two jets have equal pt we assume that they are duplicate entries. 
                        #    sys.exit('ERROR: Duplicate jets')


                        df_fjparticles_aux = None

                        for iterator, j in enumerate(cut_list):
                            df_fjparticles_aux = pd.concat([df_fjparticles_aux, df_fjparticles[j:j+1]])

                        # Add the jets to the total list
                        self.df_fjparticles = pd.concat([self.df_fjparticles, df_fjparticles_aux])
                        n_jets = self.df_fjparticles.size
                    

                        # Set labels (Z=1, QCD=0)
                        if quark_jet_filepattern in input_file:
                            y = np.ones(len(df_fjparticles_aux))
                            n_jets_quark += len(df_fjparticles_aux)
                        elif gluon_jet_filepattern in input_file:
                            y = np.zeros(len(df_fjparticles_aux))
                            n_jets_gluon += len(df_fjparticles_aux)

                        print(f' Size of the last dataset (after the cuts): {len(df_fjparticles_aux)}')
                        print(f' n_jets = {n_jets}')
                        print(f' n_jets_q = {n_jets_quark}')
                        print(f' n_jets_g = {n_jets_gluon}')
                        print()

                        if self.y is None:
                            self.y = y
                        else:
                            self.y = np.concatenate([self.y, y])
                    
                    
                    
                # n_jets will generally be more than what we want, note that it deletes the last entries -> DELETES ONLY THE QCD DATASET: SYSTEMATIC ERROR (for self.n_total >~ 10k it won't matter though )
                if n_jets  > self.n_total:
                    print(f'Number of Jets: {n_jets}')
                    self.df_fjparticles = self.df_fjparticles[:self.n_total]
                    self.y = self.y[:self.n_total]
                    n_jets = self.df_fjparticles.size
                    print(f'Final number of Jets: {n_jets}')

                print('Done!')
                print()



        # ZvsQCD Classification problem

        elif self.dataset_type == 'Zjet':            


            # Pythia Dataset

            # Loop through all .root files in specified directories, 
            # and for each one convert ROOT TTree into a SeriesGroupBy object of fastjet particles per event

            input_files = []

            if self.pt[0] == 300 and self.pt[1] == 350:
                with open("/rstorage/ml/pythia/zrootified_300_350_npthatmax/file_list.txt","r") as csvfile:
                    reader = csv.reader(csvfile)
                    for row in reader:
                        input_files += row
                    
                with open("/rstorage/ml/pythia/qcdrootified_300_350_npthatmax/file_list.txt","r") as csvfile:
                    reader = csv.reader(csvfile)
                    for row in reader:
                        input_files += row
            
            elif self.pt[0] == 500 and self.pt[1] == 550:
                with open("/rstorage/ml/pythia/zrootified_500_550_npthatmax/file_list.txt","r") as csvfile:
                    reader = csv.reader(csvfile)
                    for row in reader:
                        input_files += row
                    
                with open("/rstorage/ml/pythia/qcdrootified_500_550_npthatmax/file_list.txt","r") as csvfile:
                    reader = csv.reader(csvfile)
                    for row in reader:
                        input_files += row
            
            elif self.pt[0] == 1000 and self.pt[1] == 1100:
                with open("/rstorage/ml/pythia/zrootified_1000_1100/file_list.txt","r") as csvfile:
                    reader = csv.reader(csvfile)
                    for row in reader:
                        input_files += row
                    
                with open("/rstorage/ml/pythia/qcdrootified_1000_1100/file_list.txt","r") as csvfile:
                    reader = csv.reader(csvfile)
                    for row in reader:
                        input_files += row
            
            elif self.pt[0] == 1000 and self.pt[1] == 1050:
                with open("/rstorage/ml/pythia/zrootified_1000_1050/file_list.txt","r") as csvfile:
                    reader = csv.reader(csvfile)
                    for row in reader:
                        input_files += row
                    
                with open("/rstorage/ml/pythia/qcdrootified_1000_1050/file_list.txt","r") as csvfile:
                    reader = csv.reader(csvfile)
                    for row in reader:
                        input_files += row

            else:
                sys.exit("ERROR: Not the correct pt range")

            tree_name = 'tree_Particle_gen' # Right now we are only considering ungroomed jets
            unique_identifier =  ['run_number', 'ev_id']
            tree_columns = unique_identifier + ['ParticlePt', 'ParticleEta', 'ParticlePhi', 'ParticlePID']

            print('Convert ROOT trees to pandas dataframes...')
            print(f'    track_tree_name = {tree_name}')

            # The event numbers are only guaranteed to be consistent within a given file,
            # so we perform the groupby for each file before merging them together
            self.df_fjparticles = None
            self.y = None
            n_jets = 0
            self.n_jets_z = self.n_jets_qcd = 0
            
            self.Z_jet_filepattern= "pythia_z"
            self.QCD_jet_filepattern = "pythia_qcd"

            for i,input_file in enumerate(input_files):
                if (self.Z_jet_filepattern in input_file and self.n_jets_z < self.n_total/2.) or (self.QCD_jet_filepattern in input_file and self.n_jets_qcd < self.n_total/2.):
                    
                    print(f'Loading file {i} / {len(input_files)}... ({input_file})')

                    if self.Z_jet_filepattern in input_file:
                        z_or_qcd = 'Z'
                    elif self.QCD_jet_filepattern in input_file:
                        z_or_qcd = 'QCD'

                    
                    jet_tree = None
                    jet_df = None
                    with uproot.open(input_file)[tree_name] as jet_tree:
                        if not jet_tree:
                            raise ValueError(f'Tree {tree_name} not found in file {input_file}')
                        jet_df = uproot.concatenate(jet_tree, tree_columns, library='pd')

                    jet_df['ParticleM'] = energyflow.pids2ms(jet_df['ParticlePID'], error_on_unknown=True)
                    
                    jet_df.rename(columns={'ParticlePt': 'pt', 'ParticleEta': 'y', 'ParticlePhi': 'phi', 'ParticlePID': 'pid', 'ParticleM': 'm'}, inplace=True)
                    jet_df = jet_df.drop('pid', axis=1)

                    # (i) Group the particle dataframe by jet
                    #     jet_df_grouped is a DataFrameGroupBy object with one particle dataframe per jet
                    jet_df_grouped = jet_df.groupby(unique_identifier)
                    
                    # (ii) Transform the DataFrameGroupBy object to a SeriesGroupBy of fastjet particles
                    df_fjparticles = jet_df_grouped.apply(self.get_fjparticles)
                    
                    # Check if the kinematic cuts are satisfied           
                    
                    jet_pt_list, jet_eta_list, jet_mass_list = [], [], []

                    for iterator, jet in enumerate(df_fjparticles):
                        
                        jet_def = fj.JetDefinition(fj.antikt_algorithm, fj.JetDefinition.max_allowable_R)
                        cs = fj.ClusterSequence(jet, jet_def)
                        jet_selected = fj.sorted_by_pt(cs.inclusive_jets())[0]

                        jet_pt = jet_selected.pt()
                        jet_pt_list.append(jet_pt)

                        jet_eta = abs(jet_selected.eta())
                        jet_eta_list.append(jet_eta)
                        
                        jet_mass = jet_selected.m()
                        jet_mass_list.append(jet_mass)
                        

                    pt_cut_list,  eta_cut_list,  jet_mass_cut_list = [], [], []
                    
                    for iterator, jet_pt in enumerate(jet_pt_list):
                        if self.pt[0] <= jet_pt <= self.pt[1]:                      pt_cut_list.append(iterator)
                        if jet_eta_list[iterator] <= 1.7:                           eta_cut_list.append(iterator)
                        if self.mj_min <= jet_mass_list[iterator] <= self.mj_max:   jet_mass_cut_list.append(iterator)


                    print(f'For file {i}, that contains the {z_or_qcd} Pythia dataset, {math.trunc(100*(1-len(pt_cut_list)/len(df_fjparticles)))}% jets are outside the pt range: {self.pt[0],self.pt[1]}')                    
                    print(f'For file {i}, that contains the {z_or_qcd} Pythia dataset, {math.trunc(100*(1-len(eta_cut_list)/len(df_fjparticles)))}% jets are outside the eta range: eta <= 1.7') 
                    print(f'For file {i}, that contains the {z_or_qcd} Pythia dataset, {math.trunc(100*(1-len(jet_mass_cut_list)/len(df_fjparticles)))}% jets are outside the mass range ({self.mj_min},{self.mj_max}) GeV') 
                    print()

                    #if len(jet_pt_list) != len(set(jet_pt_list)): # The pt's have ~15 digits accuracy, so if two jets have equal pt we assume that they are duplicate entries
                    #    sys.exit('ERROR: Duplicate jets')


                    df_fjparticles_aux = None
                    cut_list = list(set(pt_cut_list) & set(eta_cut_list) & set(jet_mass_cut_list)) # The jets that satisfy both the eta and the pt cuts
                    
                    for iterator, j in enumerate(cut_list):
                        df_fjparticles_aux = pd.concat([df_fjparticles_aux, df_fjparticles[j:j+1]])
                        
                    # Add the jets to the total list
                    self.df_fjparticles = pd.concat([self.df_fjparticles, df_fjparticles_aux])
                    n_jets = self.df_fjparticles.size
                    

                    # Set labels (Z=1, QCD=0)
                    if self.Z_jet_filepattern in input_file:
                        y = np.ones(len(df_fjparticles_aux))
                        self.n_jets_z += len(df_fjparticles_aux)
                    elif self.QCD_jet_filepattern in input_file:
                        y = np.zeros(len(df_fjparticles_aux))
                        self.n_jets_qcd += len(df_fjparticles_aux)

                    print(f' Size of the last dataset (after the cuts): {len(df_fjparticles_aux)}')
                    print(f' n_jets = {n_jets}')
                    print(f' n_jets_z = {self.n_jets_z}')
                    print(f' n_jets_qcd = {self.n_jets_qcd}')
                    print()

                    if self.y is None:
                        self.y = y
                    else:
                        self.y = np.concatenate([self.y, y])
                    
            # n_jets will generally be more than what we want, note that it deletes the last entries -> Deletes only the qcd dataset: Systematic Error
            if n_jets  > self.n_total:
                print(f'Number of Jets: {n_jets}')
                self.df_fjparticles = self.df_fjparticles[:self.n_total]
                self.y = self.y[:self.n_total]
                n_jets = self.df_fjparticles.size
                print(f'Final number of Jets: {n_jets}')

            print('Done!')
            print()

            
            # Herwig Dataset
             
            if self.Herwig_dataset == 'True':
                
                input_files = []
                if self.pt[0] == 500 and self.pt[1] == 550:
                    with open("/rstorage/ml/herwig/zrootified/file_list.txt","r") as csvfile:
                        reader = csv.reader(csvfile)
                        for row in reader:
                            input_files += row
                    
                    with open("/rstorage/ml/herwig/qcdrootified/file_list.txt","r") as csvfile:
                        reader = csv.reader(csvfile)
                        for row in reader:
                            input_files += row
                else: 
                    sys.exit("ERROR: There is no Herwig dataset for the given pt range")
                    print()

                
                tree_name = 'tree_Particle_gen' # Right now we are only considering ungroomed jets
                unique_identifier =  ['run_number', 'ev_id']
                tree_columns = unique_identifier + ['ParticlePt', 'ParticleEta', 'ParticlePhi', 'ParticlePID']

                print('Convert ROOT trees to pandas dataframes...')
                print(f'    track_tree_name = {tree_name}')


                # The event numbers are only guaranteed to be consistent within a given file,
                # so we perform the groupby for each file before merging them together

                self.df_fjparticles_herwig = None
                self.y_herwig = None
                n_jets, n_jets_z, n_jets_qcd = 0, 0, 0
                Z_jet_herwig_filepattern = "herwig_gen_z_z"
                qcd_jet_herwig_filepattern = "herwig_gen_qcd_qcd"
                
                for i, input_file in enumerate(input_files): # this is unnecessary since we only have one file for now
                    if (n_jets_z >= (self.n_test + self.n_val)/2 and Z_jet_herwig_filepattern in input_file) or (n_jets_qcd >= (self.n_test + self.n_val)/2 and qcd_jet_herwig_filepattern in input_file):
                        continue
                    
                    print(f'Loading file {i} / {len(input_files)}... ({input_file})')

                    jet_tree = None
                    jet_df = None
                    with uproot.open(input_file)[tree_name] as jet_tree: #input_files and NOT input_file because there is only one file for now
                        if not jet_tree:
                            raise ValueError(f'Tree {tree_name} not found in file {input_file}')
                        jet_df = uproot.concatenate(jet_tree, tree_columns, library='pd')
                    

                    jet_df['ParticleM'] = energyflow.pids2ms(jet_df['ParticlePID'], error_on_unknown=True)
                    

                    jet_df.rename(columns={'ParticlePt': 'pt', 'ParticleEta': 'y', 'ParticlePhi': 'phi', 'ParticlePID': 'pid', 'ParticleM': 'm'}, inplace=True)
                    jet_df = jet_df.drop('pid', axis=1)

                           
                    # (i) Group the particle dataframe by jet
                    #     jet_df_grouped is a DataFrameGroupBy object with one particle dataframe per jet
                    jet_df_grouped = jet_df.groupby(unique_identifier)
                            
                    # (ii) Transform the DataFrameGroupBy object to a SeriesGroupBy of fastjet particles
                    df_fjparticles = jet_df_grouped.apply(self.get_fjparticles)

                    # Check if the kinematic cuts are satisfied           
                    
                    jet_pt_list, jet_eta_list, jet_mass_list = [], [], []

                    for iterator, jet in enumerate(df_fjparticles):
                        
                        jet_def = fj.JetDefinition(fj.antikt_algorithm, fj.JetDefinition.max_allowable_R)
                        cs = fj.ClusterSequence(jet, jet_def)
                        jet_selected = fj.sorted_by_pt(cs.inclusive_jets())[0]

                        jet_pt = jet_selected.pt()
                        jet_pt_list.append(jet_pt)

                        jet_eta = abs(jet_selected.eta())
                        jet_eta_list.append(jet_eta)
                        
                        jet_mass = jet_selected.m()
                        jet_mass_list.append(jet_mass)
                        

                    pt_cut_list,  eta_cut_list,  jet_mass_cut_list = [], [], []
                    
                    for iterator, jet_pt in enumerate(jet_pt_list):
                        if self.pt[0]<= jet_pt <= self.pt[1]:  pt_cut_list.append(iterator)
                        if jet_eta_list[iterator] <= 1.7:     eta_cut_list.append(iterator)
                        if jet_mass_list[iterator] >= self.mj_min  and  jet_mass_list[iterator] <= self.mj_max: 
                            jet_mass_cut_list.append(iterator)

                    cut_list = list(set(pt_cut_list) & set(eta_cut_list) & set(jet_mass_cut_list)) # The jets that satisfy all the cuts

                    df_fjparticles_aux = None
                    for iterator, j in enumerate(cut_list):
                        df_fjparticles_aux = pd.concat([df_fjparticles_aux, df_fjparticles[j:j+1]])

                    # Add the jets to the total list
                    self.df_fjparticles_herwig = pd.concat([self.df_fjparticles_herwig, df_fjparticles_aux])
                    n_jets_file = df_fjparticles_aux.size
                    n_jets += n_jets_file     

                    # Set labels (Z=1, QCD=0)
                      
                    if Z_jet_herwig_filepattern in input_file: #We read the Z file first
                        z_or_qcd = 'Z'
                        n_jets_z += n_jets_file
                        if n_jets_z > (self.n_val + self.n_test)/2:
                            n_jets_file -= ( n_jets - (self.n_test + self.n_val + 1)//2)
                            self.df_fjparticles_herwig = self.df_fjparticles_herwig[:(self.n_test + self.n_val + 1)//2]
                            n_jets = self.df_fjparticles_herwig.size
                            n_jets_z = (self.n_test + self.n_val + 1)//2
                            print(f"Final number of z jets in the dataset: {n_jets_z}")
                            print()
                        y = np.ones(n_jets_file)
                        
                    elif qcd_jet_herwig_filepattern in input_file:
                        z_or_qcd = 'QCD'
                        y = np.zeros(n_jets_file)
                        n_jets_qcd += n_jets_file

                    #if len(jet_pt_list) != len(set(jet_pt_list)): # The pt's have ~15 digits accuracy, so if two jets have equal pt we assume that they are duplicate entries
                    #    sys.exit('ERROR: Duplicate jets')



                    print(f'For file {i}, that contains the {z_or_qcd} Herwig dataset, {math.trunc(100*(1-len(pt_cut_list)/len(df_fjparticles)))}% jets are outside the pt range: [{self.pt[0],self.pt[1]}] GeV')                    
                    print(f'For file {i}, that contains the {z_or_qcd} Herwig dataset, {math.trunc(100*(1-len(eta_cut_list)/len(df_fjparticles)))}% jets are outside the eta range:  eta <= 1.7') 
                    print(f'For file {i}, that contains the {z_or_qcd} Herwig dataset, {math.trunc(100*(1-len(jet_mass_cut_list)/len(df_fjparticles)))}% jets are outside the mass range: [{self.mj_min},{self.mj_max}] GeV') 
                    print()


                    print(f"Number of jets that satisfy the cuts: {len(cut_list)}")

                    print(f' Size of the last dataset (after the cuts): {n_jets_file}')
                    print(f' n_jets = {n_jets}')
                    print()

                    if self.y_herwig is None:
                        self.y_herwig = y
                    else:
                        self.y_herwig = np.concatenate([self.y_herwig, y])
                        
                    if n_jets >= self.n_test + self.n_val:  # We dont need more datapoint
                        break   

                # n_jets will generally be more than what we want, note that it deletes the last entries -> Deletes only the g dataset: Systematic Error
                if n_jets  > self.n_test + self.n_val:
                    print(f'Number of Herwig Jets: {n_jets}')
                    self.df_fjparticles_herwig = self.df_fjparticles_herwig[:self.n_test + self.n_val]
                    self.y_herwig = self.y_herwig[:self.n_test + self.n_val]
                    n_jets = self.df_fjparticles_herwig.size
                    print(f'Final number of Herwig Jets: {n_jets}')
                print('Done!')
                print()




    #---------------------------------------------------------------
    # Main processing function
    #---------------------------------------------------------------
    def process_qg(self):

        # Loop over events and do jet finding
        # Fill each of the jet_variables into a list
        fj.ClusterSequence.print_banner()
        print('Finding jets and computing N-subjettiness and subjets...')


        # PYTHIA DATASET 
        
        result = [self.analyze_event(fj_particles, 'pythia') for fj_particles in self.df_fjparticles]
        

        # Leading Angle
        
        for r in self.r_list:
                for N in self.N_cluster_list:
                    for col in range(self.n_total):
                        count_q=0
                        count_g=0
                        if self.y[col] == 1:
                            count_q = self.output['leading_angle'][f'r{r}_N{N}'][col]
                            self.output['leading_angle'][f'r{r}_N{N}_q'].append(count_q)
                        if self.y[col] == 0:
                            count_g = self.output['leading_angle'][f'r{r}_N{N}'][col]
                            self.output['leading_angle'][f'r{r}_N{N}_g'].append(count_g)


        # Subjet Multiplicity

        zcut = 0.0

        for r in self.r_list:
            for N in self.N_cluster_list:
                for col in range(self.n_total):
                    count_q=0
                    count_g=0
                    if self.y[col] == 1:
                        for row in range(N):
                            if self.output[f'subjet'][f'r{r}_N{N}_z'][col][row] > zcut:
                                count_q+= math.ceil(self.output[f'subjet'][f'r{r}_N{N}_z'][col][row])
                        self.output['subjet_multiplicity'][f'r{r}_N{N}_q'].append(count_q)
                    if self.y[col] == 0:
                        for row in range(N):
                            if self.output[f'subjet'][f'r{r}_N{N}_z'][col][row] > zcut:
                                count_g+= math.ceil(self.output[f'subjet'][f'r{r}_N{N}_z'][col][row])
                        self.output['subjet_multiplicity'][f'r{r}_N{N}_g'].append(count_g)

                print()
                print(f'r = {r}, N = {N}')
                print(f'Z or q dataset,   average subjet multiplicity, median subjet multiplicity and max number of subjets:')
                print(statistics.mean(self.output['subjet_multiplicity'][f'r{r}_N{N}_q']), statistics.median(self.output['subjet_multiplicity'][f'r{r}_N{N}_q']), max(self.output['subjet_multiplicity'][f'r{r}_N{N}_q']))
                print(f'QCD or g dataset, average subjet multiplicity, median subjet multiplicity and max number of subjets:')
                print(statistics.mean(self.output['subjet_multiplicity'][f'r{r}_N{N}_g']), statistics.median(self.output['subjet_multiplicity'][f'r{r}_N{N}_g']), max(self.output['subjet_multiplicity'][f'r{r}_N{N}_g']))
            
        


        # Hardest Subjet Momenta Distribution
        
        for r in self.r_list:
            for N in self.N_cluster_list:
                for col in range(self.n_total):
                    z_q=0
                    z_g=0
                    if self.y[col] == 1:
                      #  for row in range(N):
                        z_q = self.output[f'subjet'][f'r{r}_N{N}_z'][col][0]
                        self.output['hardest_subjet_z'][f'r{r}_N{N}_q'].append(z_q)
                    if self.y[col] == 0:
                        #for row in range(N):
                        z_g = self.output[f'subjet'][f'r{r}_N{N}_z'][col][0]
                        self.output['hardest_subjet_z'][f'r{r}_N{N}_g'].append(z_g)
        
        # 4 Hardest Subjet Momenta Distribution
        
        for r in self.r_list:
            for N in self.N_cluster_list:
                for col in range(self.n_total):
                    z_q=0
                    z_g=0
                    if self.y[col] == 1:
                        z_q1 = self.output[f'subjet'][f'r{r}_N{N}_z'][col][0]
                        try: 
                            z_q2 = self.output[f'subjet'][f'r{r}_N{N}_z'][col][1]
                        except:
                            z_q2 = 0
                        try:
                            z_q3 = self.output[f'subjet'][f'r{r}_N{N}_z'][col][2]
                        except:
                            z_q3 = 0
                        
                        self.output['3_hardest_subjets_z'][f'r{r}_N{N}_q1'].append(z_q1)
                        self.output['3_hardest_subjets_z'][f'r{r}_N{N}_q2'].append(z_q2)
                        self.output['3_hardest_subjets_z'][f'r{r}_N{N}_q3'].append(z_q3)
                    if self.y[col] == 0:
                        z_g1 = self.output[f'subjet'][f'r{r}_N{N}_z'][col][0]
                        try: 
                            z_g2 = self.output[f'subjet'][f'r{r}_N{N}_z'][col][1]
                        except:
                            z_g2 = 0
                        try:
                            z_g3 = self.output[f'subjet'][f'r{r}_N{N}_z'][col][2]
                        except:
                            z_g3 = 0
                        
                        self.output['3_hardest_subjets_z'][f'r{r}_N{N}_g1'].append(z_g1)
                        self.output['3_hardest_subjets_z'][f'r{r}_N{N}_g2'].append(z_g2)
                        self.output['3_hardest_subjets_z'][f'r{r}_N{N}_g3'].append(z_g3)
        
        
        # WTA Subjet Momenta Distribution
        self.wta_axis= 'False'
        if self.wta_axis == 'True':
            for r in self.r_list:
                for N in self.N_cluster_list:
                    for col in range(self.n_total):
                        z_q=0
                        z_g=0
                        if self.y[col] == 1:
                            z_q = self.output[f'subjet'][f'r{r}_N{N}_z'][col][self.output['wta_subjet'][f'r{r}_N{N}'][col]]
                            self.output['wta_subjet_z'][f'r{r}_N{N}_q'].append(z_q)
                        if self.y[col] == 0:
                            z_g = self.output[f'subjet'][f'r{r}_N{N}_z'][col][self.output['wta_subjet'][f'r{r}_N{N}'][col]]
                            self.output['wta_subjet_z'][f'r{r}_N{N}_g'].append(z_g)


        # Subjet Momenta Distribution
        
        z_cut = 0
        for r in self.r_list:
            for N in self.N_cluster_list:
                for col in range(self.n_total):
                    z_q=0
                    z_g=0
                    if self.y[col] == 1:
                        for row in range(N):
                            z_q = self.output[f'subjet'][f'r{r}_N{N}_z'][col][row]
                            if z_q >= z_cut:
                                self.output['subjet_z'][f'r{r}_N{N}_q'].append(z_q)
                    if self.y[col] == 0:
                        for row in range(N):
                            z_g = self.output[f'subjet'][f'r{r}_N{N}_z'][col][row]
                            if z_g >= z_cut:
                                self.output['subjet_z'][f'r{r}_N{N}_g'].append(z_g)

        
        # HERWIG DATASET 

        if self.Herwig_dataset == 'True':

            print()
            print("Herwig Dataset:")
            result = [self.analyze_event(fj_particles, 'herwig') for fj_particles in self.df_fjparticles_herwig]            
            
            for r in self.r_list:
                for N in self.N_cluster_list:
                    for col in range(self.n_val + self.n_test):
                        count_q=0
                        count_g=0
                        if self.y_herwig[col] == 1:
                            for row in range(N):
                                if self.output[f'subjet'][f'herwig_r{r}_N{N}_z'][col][row] > zcut:
                                    count_q+= math.ceil(self.output[f'subjet'][f'herwig_r{r}_N{N}_z'][col][row])
                            self.output['subjet_multiplicity'][f'herwig_r{r}_N{N}_q'].append(count_q)
                        if self.y_herwig[col] == 0: 
                            for row in range(N):
                                if self.output[f'subjet'][f'herwig_r{r}_N{N}_z'][col][row] > zcut:
                                    count_g+= math.ceil(self.output[f'subjet'][f'herwig_r{r}_N{N}_z'][col][row])
                            self.output['subjet_multiplicity'][f'herwig_r{r}_N{N}_g'].append(count_g)
                            

                    print()
                    print(f'r = {r}, N = {N}')
                    print(f'Z dataset Herwig, average subjet multiplicity and max number of subjets:')
                    print(sum(self.output['subjet_multiplicity'][f'herwig_r{r}_N{N}_q'])/len(self.output['subjet_multiplicity'][f'herwig_r{r}_N{N}_q']), max(self.output['subjet_multiplicity'][f'herwig_r{r}_N{N}_q']))
                    print(f'QCD dataset Herwig, average subjet multiplicity and max number of subjets:')
                    print(sum(self.output['subjet_multiplicity'][f'herwig_r{r}_N{N}_g'])/len(self.output['subjet_multiplicity'][f'herwig_r{r}_N{N}_g']), max(self.output['subjet_multiplicity'][f'herwig_r{r}_N{N}_g']))
        

            # Leading Angle
            
            for r in self.r_list:
                    for N in self.N_cluster_list:
                        for col in range(self.n_val + self.n_test):
                            count_q=0
                            count_g=0
                            if self.y_herwig[col] == 1:
                                count_q = self.output['leading_angle'][f'herwig_r{r}_N{N}'][col]
                                self.output['leading_angle'][f'herwig_r{r}_N{N}_q'].append(count_q)
                            if self.y_herwig[col] == 0:
                                count_g = self.output['leading_angle'][f'herwig_r{r}_N{N}'][col]
                                self.output['leading_angle'][f'herwig_r{r}_N{N}_g'].append(count_g)
                                
            # 3 Hardest Momenta

            for r in self.r_list:
                for N in self.N_cluster_list:
                    for col in range(self.n_val + self.n_test):
                        if self.y_herwig[col] == 1:
                            z_q1 = self.output[f'subjet'][f'herwig_r{r}_N{N}_z'][col][0]
                            try: 
                                z_q2 = self.output[f'subjet'][f'herwig_r{r}_N{N}_z'][col][1]
                            except:
                                z_q2 = 0
                            try:
                                z_q3 = self.output[f'subjet'][f'herwig_r{r}_N{N}_z'][col][2]
                            except:
                                z_q3 = 0
                            
                            self.output['3_hardest_subjets_z'][f'herwig_r{r}_N{N}_q1'].append(z_q1)
                            self.output['3_hardest_subjets_z'][f'herwig_r{r}_N{N}_q2'].append(z_q2)
                            self.output['3_hardest_subjets_z'][f'herwig_r{r}_N{N}_q3'].append(z_q3)

                        if self.y_herwig[col] == 0:
                            z_g1 = self.output[f'subjet'][f'herwig_r{r}_N{N}_z'][col][0]
                            try: 
                                z_g2 = self.output[f'subjet'][f'herwig_r{r}_N{N}_z'][col][1]
                            except:
                                z_g2 = 0
                            try:
                                z_g3 = self.output[f'subjet'][f'herwig_r{r}_N{N}_z'][col][2]
                            except:
                                z_g3 = 0
                            
                            self.output['3_hardest_subjets_z'][f'herwig_r{r}_N{N}_g1'].append(z_g1)
                            self.output['3_hardest_subjets_z'][f'herwig_r{r}_N{N}_g2'].append(z_g2)
                            self.output['3_hardest_subjets_z'][f'herwig_r{r}_N{N}_g3'].append(z_g3)
        

        # Transform the dictionary of lists into a dictionary of numpy arrays
        self.output_numpy = {}
        for key,value in self.output.items():
            self.output_numpy[key] = self.transform_to_numpy(value)

        
        # Reformat output for ML algorithms (array with 1 array per jet which contain all N-subjettiness values)
        self.output_final = {}
        self.output_final['nsub'] = np.array([list(self.output_numpy['nsub'].values())])[0].T
        
        for key,val in self.output_numpy['subjet'].items():
            self.output_final[f'subjet_{key}'] = val
            print(key)

        # Write jet arrays to file
        with h5py.File(os.path.join(self.output_dir, 'subjets_unshuffled.h5'), 'w') as hf:
            print('-------------------------------------')

            # Write labels: gluon 0, quark 1
            hf.create_dataset(f'y', data=self.y)
            print(f'labels: {self.y.shape}')
            
            if self.Herwig_dataset == 'True':
                hf.create_dataset(f'y_herwig', data=self.y_herwig)


            # Write numpy arrays
            for key,val in self.output_final.items():
                hf.create_dataset(key, data=val)
                print(f'{key}: {val.shape}')

                # Check whether any training entries are empty
                [print(f'WARNING: input entry {i} is empty') for i,x in enumerate(val) if not x.any()]

            for qa_observable in self.output['qa']:
                hf.create_dataset(f'{qa_observable}', data=self.output_numpy['qa'][qa_observable])
                print(f'{qa_observable}')

            # Make some QA plots
            self.plot_QA()

            # Store some info on the output directory so that we don't need to remember the exact details of the config when we run the code at a later date

            hf.create_dataset('N_list', data=self.N_list)
            hf.create_dataset('beta_list', data=self.beta_list)
            hf.create_dataset('r_list', data=self.r_list)
            hf.create_dataset('N_max', data=self.N_max_list)
            hf.create_dataset('n_total', data = self.n_total)
            hf.create_dataset('Clustering_Alg', data = self.Clustering_Alg)
            hf.create_dataset('Laman_construction', data = self.Laman_construction)
            hf.create_dataset('N_clustering', data = self.N_cluster_list)   
            hf.create_dataset('Herwig_dataset', data = self.Herwig_dataset)        

            

    #---------------------------------------------------------------
    # Process an event
    #---------------------------------------------------------------
    def analyze_event(self, fj_particles, dataset_choice):
    
        # Check that the entries exist appropriately
        if fj_particles and type(fj_particles) != fj.vectorPJ:
            print('fj_particles type mismatch -- skipping event')
            return

        # Find jets -- one jet per "event".  We only use antikt for the Jet Clustering
        jet_def = fj.JetDefinition(fj.antikt_algorithm, fj.JetDefinition.max_allowable_R)

        cs = fj.ClusterSequence(fj_particles, jet_def)
        jet_selected = fj.sorted_by_pt(cs.inclusive_jets())[0]

        # Compute jet quantities and store in our data structures
        self.analyze_jets(jet_selected, dataset_choice)

        self.event_index += 1
        if self.event_index%1000 == 0:
            print(f'event: {self.event_index}  --  {int(time.time() - self.start_time)}s')

    #---------------------------------------------------------------
    # Analyze jets of a given event.
    #---------------------------------------------------------------
    def analyze_jets(self, jet_selected, dataset_choice):
        self.fill_nsubjettiness(jet_selected, dataset_choice)
        self.fill_subjets(jet_selected, dataset_choice)
        self.fill_qa(jet_selected)

    #---------------------------------------------------------------
    # Compute Nsubjettiness of jet
    #---------------------------------------------------------------
    def fill_nsubjettiness(self, jet, dataset_choice):
        
        axis_definition = fjcontrib.KT_Axes() # Naive (?) choice
        axis_definition2 = fjcontrib.OnePass_KT_Axes() # What we used in the JFN paper that works fine because its a recoil free axis definition. 
        for i,N in enumerate(self.N_list):
            
            beta = self.beta_list[i]
            measure_definition = fjcontrib.UnnormalizedMeasure(beta)
            n_subjettiness_calculator = fjcontrib.Nsubjettiness(N, axis_definition2, measure_definition)
            n_subjettiness = n_subjettiness_calculator.result(jet)/jet.pt()
            
            self.output['nsub'][f'N{N}_beta{beta}'].append(n_subjettiness)


            if dataset_choice =='Herwig':
                beta = self.beta_list[i]
                measure_definition = fjcontrib.UnnormalizedMeasure(beta)
                n_subjettiness_calculator = fjcontrib.Nsubjettiness(N, axis_definition2, measure_definition)
                n_subjettiness = n_subjettiness_calculator.result(jet)/jet.pt()
                self.output['nsub_herwig'][f'N{N}_beta{beta}'].append(n_subjettiness)



    #---------------------------------------------------------------
    # Compute subjet kinematics...
    #---------------------------------------------------------------
    def fill_subjets(self, jet, dataset_choice):
        
        if self.subjet_basis == 'inclusive':
            self.N_cluster_list = self.N_max_list
        elif self.subjet_basis == 'exclusive':
            self.N_cluster_list = self.njet_list
        else:
            sys.exit(f'ERROR: Invalid choice for subjet_basis')

        # Pt sorted hadrons
        if dataset_choice == 'pythia':
            self.output['Jet_Mass']['mass'].append(jet.m())

        hadrons_aux  = fj.sorted_by_pt(jet.constituents())

        # WTA Axes

        jet_def_wta = fj.JetDefinition(fj.kt_algorithm, 2*self.R) #to cluster the whole jet again, with WTA this time
        jet_def_wta.set_recombination_scheme(fj.WTA_pt_scheme)

        reclusterer_wta = fjcontrib.Recluster(jet_def_wta)
        jet_wta = reclusterer_wta.result(jet)

        for r in self.r_list:

            if self.Clustering_Alg == 'kt_algorithm':
                subjet_def = fj.JetDefinition(fj.kt_algorithm, r)
            elif self.Clustering_Alg == 'antikt_algorithm':
                subjet_def = fj.JetDefinition(fj.antikt_algorithm, r)
            elif self.Clustering_Alg == 'cambridge_algorithm':
                subjet_def = fj.JetDefinition(fj.cambridge_algorithm, r)
            else:
                sys.exit(f'ERROR: Wrong Clustering_Algorithm.')

            cs_subjet = fj.ClusterSequence(jet.constituents(), subjet_def)
            

            # To find which subjet contains the WTA axes, i.e. WTA subjet
            for N_cluster in self.N_cluster_list:

                if self.subjet_basis == 'inclusive':
                    subjets = fj.sorted_by_pt(cs_subjet.inclusive_jets())
                elif self.subjet_basis == 'exclusive':
                    subjets = fj.sorted_by_pt(cs_subjet.exclusive_jets_up_to(N_cluster))


                # Which hadron has the same axis as the WTA jet
                for N in range(len(hadrons_aux)):
                    deltaR_wtahadron = jet_wta.delta_R(hadrons_aux[N])
                    if deltaR_wtahadron==0:
                        wtahadron=N
                        break 
                
                # In which subjet does it belong to
                for i in range(len(subjets)):
                    for j in range(len(subjets[i].constituents())):
                        deltaR_wtasubjet = subjets[i].constituents()[j].delta_R(hadrons_aux[wtahadron])
                        if deltaR_wtasubjet==0:
                            wtasubjet=i
                            self.output['wta_subjet'][f'r{r}_N{N_cluster}'].append(wtasubjet)
                            # Break the loop to save time
                            break 
                    else:
                        # Continue if the inner loop wasn't broken.
                        continue
                    # Inner loop was broken, break the outer
                    break        


            # Construct a Laman graph for each jet, and save the edges (node connections) and angles
            for N_cluster in self.N_cluster_list:

                edges_list = []
                angles_list = []
                subjet_phi_list=[]
                subjet_rap_list=[]
                z_list = []
                leading_angle = []
                if self.subjet_basis == 'inclusive':
                    subjets = fj.sorted_by_pt(cs_subjet.inclusive_jets())
                elif self.subjet_basis == 'exclusive':
                    subjets = fj.sorted_by_pt(cs_subjet.exclusive_jets_up_to(N_cluster))

                zcut = 0.0
                for N in range(N_cluster): #the max number of N is N_max-1 because we start from 0
                    # First, fill the z values of the node + (η,φ) for the subjets
                    if N < len(subjets):
                        z = subjets[N].pt()/jet.pt()
                        if z > zcut:
                            z_list.append(z)
                            subjet_phi = subjets[N].phi()
                            subjet_rap = subjets[N].rap()
                            subjet_phi_list.append(subjet_phi)
                            subjet_rap_list.append(subjet_rap)
                        else:
                            z_list.append(0)
                            subjet_phi_list.append(0)
                            subjet_rap_list.append(0)

                    else:
                        z_list.append(0)
                        subjet_phi_list.append(0)
                        subjet_rap_list.append(0)
                    
                    #Leading Angle

                    if len(subjets)>=2:
                        if N==1:
                            leading_angle.append(subjets[0].delta_R(subjets[1]))
                    else:
                        if N==1:                        # Shouldn't this be N==0?
                            leading_angle.append(0) 



                    # Henneberg construction using Type 1 connections
                    # To start, let's just build based on pt ordering
                    # A simple construction is to have each node N connected to nodes N+1,N+2
                    # We will also zero-pad for now (edges denoted [-1,-1]) to keep fixed-size arrays

                    if self.laman_load == 'True':
                        if self.Laman_construction == 'naive':
                            if N < N_cluster-1: 
                                if N < len(subjets)-1: 
                                    angle = subjets[N].delta_R(subjets[N+1])
                                    edges_list.append(np.array([N, N+1])) #in order to know to which pair the angle's list entry corresponds to 
                                    angles_list.append(angle)
                                else:
                                    edges_list.append(np.array([-1, -1]))
                                    angles_list.append(0)

                            if N < N_cluster-2:
                                if N < len(subjets)-2:
                                    angle = subjets[N].delta_R(subjets[N+2])
                                    edges_list.append(np.array([N, N+2]))
                                    angles_list.append(angle) 
                                else:
                                    edges_list.append(np.array([-1, -1]))
                                    angles_list.append(0)

                        elif self.Laman_construction == '1N':
                            if N == 0:
                                for i in range(N_cluster-1): # Because we want to start from i=1 
                                    if i < len(subjets)-1:
                                        angle = subjets[0].delta_R(subjets[i+1])
                                        edges_list.append(np.array([0, i+1])) #in order to know to which pair the angle's list entry corresponds to 
                                        angles_list.append(angle)
                                    else:
                                        edges_list.append(np.array([0, -1]))
                                        angles_list.append(0)
                                
                            elif N < N_cluster-1:
                                if N < len(subjets)-1:
                                    angle = subjets[N].delta_R(subjets[N+1])
                                    edges_list.append(np.array([N, N+1]))
                                    angles_list.append(angle) 
                                else:
                                    edges_list.append(np.array([-1, -1]))
                                    angles_list.append(0)

                        elif self.Laman_construction == '1N2N':
                            if N == 0:
                                for i in range(len(subjets)-1): # Because we want to start from i=1
                                    if i < len(subjets)-1:
                                        angle = subjets[0].delta_R(subjets[i+1])
                                        edges_list.append(np.array([0, i+1])) # In order to know to which pair the angle's list entry corresponds to 
                                        angles_list.append(angle)
                                    else:
                                        edges_list.append(np.array([0, -1]))
                                        angles_list.append(0)
                            elif N == 1:
                                for i in range(len(subjets)-2): # Because we want to start from i=2
                                    if i < len(subjets)-2:
                                        angle = subjets[1].delta_R(subjets[i+2])
                                        edges_list.append(np.array([1, i+2])) # In order to know to which pair the angle's list entry corresponds to 
                                        angles_list.append(angle)
                                    else:
                                        edges_list.append(np.array([1, -1]))
                                        angles_list.append(0)         
                        else:
                            sys.exit(f'Wrong Laman Construction Algorithm.')

                

                if dataset_choice == 'pythia':
                    if self.laman_load == 'True':
                        self.output[f'subjet'][f'r{r}_N{N_cluster}_edges'].append(np.array(edges_list))
                        self.output[f'subjet'][f'r{r}_N{N_cluster}_angles'].append(np.array(angles_list))
                    self.output[f'subjet'][f'r{r}_N{N_cluster}_z'].append(np.array(z_list))
                    self.output[f'subjet'][f'r{r}_N{N_cluster}_sub_phi'].append(np.array(subjet_phi_list))
                    self.output[f'subjet'][f'r{r}_N{N_cluster}_sub_rap'].append(np.array(subjet_rap_list))
                    self.output[f'leading_angle'][f'r{r}_N{N_cluster}'].append(leading_angle)

                    
                    
                elif dataset_choice == 'herwig':
                    if self.laman_load == 'True':
                        self.output[f'subjet'][f'herwig_r{r}_N{N_cluster}_edges'].append(np.array(edges_list))
                        self.output[f'subjet'][f'herwig_r{r}_N{N_cluster}_angles'].append(np.array(angles_list))
                    self.output[f'subjet'][f'herwig_r{r}_N{N_cluster}_z'].append(np.array(z_list))
                    self.output[f'subjet'][f'herwig_r{r}_N{N_cluster}_sub_phi'].append(np.array(subjet_phi_list))
                    self.output[f'subjet'][f'herwig_r{r}_N{N_cluster}_sub_rap'].append(np.array(subjet_rap_list))
                    self.output[f'leading_angle'][f'herwig_r{r}_N{N_cluster}'].append(leading_angle)
                else: 
                    sys.exit(f'Error: Wrong dataset choice.')
                
            
    #---------------------------------------------------------------
    # Analyze jets of a given event.
    #---------------------------------------------------------------

    def fill_qa(self, jet):

        # Fill some jet QA
        self.output['qa']['jet_pt'].append(jet.pt())
        
        # angularity
        alpha = 1
        kappa = 1
        angularity = fjext.lambda_beta_kappa(jet, alpha, kappa, self.R)
        self.output['qa']['jet_angularity'].append(angularity)

        # thrust
        alpha = 2
        kappa = 1
        angularity = fjext.lambda_beta_kappa(jet, alpha, kappa, self.R)
        self.output['qa']['thrust'].append(angularity)

        # LHA
        alpha = 0.5
        kappa = 1
        angularity = fjext.lambda_beta_kappa(jet, alpha, kappa, self.R)
        self.output['qa']['LHA'].append(angularity)

        # pTD
        alpha = 0
        kappa = 2
        angularity = fjext.lambda_beta_kappa(jet, alpha, kappa, self.R)
        self.output['qa']['pTD'].append(angularity)
        
        # mass
        self.output['qa']['jet_mass'].append(jet.m())
        
        # theta_g
        beta = 0
        zcut = 0.2
        gshop = fjcontrib.GroomerShop(jet, self.R, fj.cambridge_algorithm)
        jet_groomed_lund = gshop.soft_drop(beta, zcut, self.R)
        theta_g = jet_groomed_lund.Delta() / self.R
        self.output['qa']['jet_theta_g'].append(theta_g)

        # zg
        zg = jet_groomed_lund.z()
        self.output['qa']['zg'].append(zg)
        
        # multiplicity
        n_constituents = len(jet.constituents())
        self.output['qa']['multiplicity_0000'].append(n_constituents)
        multiplicity_0150 = 0
        multiplicity_0500 = 0
        multiplicity_1000 = 0
        for constituent in jet.constituents():
            if constituent.pt() > 0.15:
                multiplicity_0150 += 1
            if constituent.pt() > 0.5:
                multiplicity_0500 += 1
            if constituent.pt() > 1.:
                multiplicity_1000 += 1
        self.output['qa']['multiplicity_0150'].append(multiplicity_0150)
        self.output['qa']['multiplicity_0500'].append(multiplicity_0500)
        self.output['qa']['multiplicity_1000'].append(multiplicity_1000)
        
    #---------------------------------------------------------------
    # Transform dictionary of lists into a dictionary of numpy arrays
    #---------------------------------------------------------------
    def transform_to_numpy(self, jet_variables_list):

        jet_variables_numpy = {}
        for key,val in jet_variables_list.items():
            jet_variables_numpy[key] = np.array(val)
        
        return jet_variables_numpy

    #---------------------------------------------------------------
    # Plot QA
    #---------------------------------------------------------------

    def plot_QA(self):
        

        # Enable Latex
        plt.rcParams['text.usetex'] = True
        plt.rc('font', family='serif',size=16)


        #  Leading Angle Histogram

        for leading_angle in self.output_numpy['leading_angle'].keys():
            
            mult_result = self.output_numpy['leading_angle'][leading_angle]
            mult_observable_shape = mult_result.shape

            for r in self.r_list:
                for N in self.N_cluster_list:
                    if leading_angle == (f'r{r}_N{N}_q'):
                        max = np.amax(mult_result)
                        bins = np.arange(0.01, 2*self.R, 0.01)
                        if self.dataset_type == 'Zjet':
                            plt.hist(mult_result, bins,histtype='step', density=True, label = 'Z', linewidth=2, linestyle='-', alpha=0.5)
                        else:
                            plt.hist(mult_result, bins,histtype='step', density=True, label = 'q', linewidth=2, linestyle='-', alpha=0.5)
                    elif leading_angle == (f'r{r}_N{N}_g'):
                        if self.dataset_type == 'Zjet':
                            plt.hist(mult_result, bins, histtype='step', density=True, label = 'QCD', linewidth=2, linestyle='-', alpha=0.5)
                        else:    
                            plt.hist(mult_result, bins, histtype='step', density=True, label = 'g', linewidth=2, linestyle='-', alpha=0.5)
                        plt.legend(loc='best', fontsize=14, frameon=True)
                        plt.ylabel('\\textit{Density}', fontsize=20)
                        plt.grid(True)
                        plt.tight_layout()
                        plt.savefig(os.path.join(self.output_dir, f'leading angle r={r}, N={N}.pdf'))
                        plt.close()



        # Jet Mass
        jet_mass_q, jet_mass_g = [], []

        for col in range(self.n_total):
            if self.y[col] == 1:
                jet_mass_q.append(self.output['Jet_Mass']['mass'][col])
            else:
                jet_mass_g.append(self.output['Jet_Mass']['mass'][col])
        
        bin_size = 2
        weights_q= np.ones_like(jet_mass_q)/float(len(jet_mass_q))/bin_size
        weights_g= np.ones_like(jet_mass_g)/float(len(jet_mass_g))/bin_size
        bins = np.arange(0., 204, bin_size)

        if self.dataset_type == 'Zjet':
            plt.hist(jet_mass_q,
                    bins, weights = weights_q,
                    histtype='step',
                    label = 'Z',
                    linewidth=2,
                    linestyle='-',
                    alpha=0.5)
            plt.hist(jet_mass_g,
                    bins, weights = weights_g,
                    histtype='step',
                    label = 'QCD',
                    linewidth=2,
                    linestyle='-',
                    alpha=0.5)
        else:
            plt.hist(jet_mass_q,
                    bins, weights = weights_q,
                    histtype='step',
                    label = 'q',
                    linewidth=2,
                    linestyle='-',
                    alpha=0.5)
            plt.hist(jet_mass_g,
                    bins, weights = weights_g,
                    histtype='step',
                    label = 'g',
                    linewidth=2,
                    linestyle='-',
                    alpha=0.5)
        plt.xlim([0,200])
        plt.legend(loc='best', fontsize=21,  frameon=True, shadow = True, edgecolor = "black")
        plt.xlabel(r"$m_j$" " (GeV)", fontsize=25)
        plt.ylabel(r"$1/\sigma \cdot d\sigma/dm_j $", fontsize=25)
        plt.yticks(fontsize=18)
        plt.xticks(fontsize=18)
        plt.grid(True)
        plt.tight_layout()
        plt.savefig(os.path.join(self.output_dir, f'jet_mass_mj.pdf'))
        plt.close() 




        # Subjet Multiplicity

        for subjet_multiplicity_observable in self.output_numpy['subjet_multiplicity'].keys():

            mult_result = self.output_numpy['subjet_multiplicity'][subjet_multiplicity_observable]
            mult_observable_shape = mult_result.shape

            for r in self.r_list:
                for N in self.N_cluster_list:
                    if subjet_multiplicity_observable.endswith(f'r{r}_N{N}_q'):
                        # Plot distributions
                        if self.subjet_basis == 'exclusive':
                            plt.xlabel(f'Pythia,  {self.subjet_basis} clust., {self.Clustering_Alg}, N={N}', fontsize=10)
                        if self.subjet_basis == 'inclusive':
                            plt.xlabel(f'Pythia,  {self.subjet_basis} clust., {self.Clustering_Alg}, r={r}', fontsize=10)
                        max = np.amax(mult_result)
                        bins = np.arange(0., N, 2.)
                        if self.dataset_type == 'Zjet':
                            plt.hist(mult_result,
                                    bins,
                                    histtype='step',
                                    density=True,
                                    label = 'Z',
                                    linewidth=2,
                                    linestyle='-',
                                    alpha=0.5)
                        else:
                            plt.hist(mult_result,
                                    bins,
                                    histtype='step',
                                    density=True,
                                    label = 'q',
                                    linewidth=2,
                                    linestyle='-',
                                    alpha=0.5)
                    elif subjet_multiplicity_observable.endswith(f'r{r}_N{N}_g'):
                        if self.dataset_type == 'Zjet':
                            plt.hist(mult_result,
                                    bins,
                                    histtype='step',
                                    density=True,
                                    label = 'QCD',
                                    linewidth=2,
                                    linestyle='-',
                                    alpha=0.5)
                        else:
                            plt.hist(mult_result,
                                    bins,
                                    histtype='step',
                                    density=True,
                                    label = 'g',
                                    linewidth=2,
                                    linestyle='-',
                                    alpha=0.5)
                        plt.legend(loc='best', fontsize=14, frameon=True)
                        plt.ylabel('\\textit{Density}', fontsize=20)
                        plt.tight_layout()
                        plt.savefig(os.path.join(self.output_dir, f'subjet multiplicity r={r}, N={N}.pdf'))
                        plt.close()  
                    
        

        # Hardest subjet z distribution

        for hardest_subjet_z_observable in self.output_numpy['hardest_subjet_z'].keys():

            mult_result = self.output_numpy['hardest_subjet_z'][hardest_subjet_z_observable]
            mult_observable_shape = mult_result.shape

            for r in self.r_list:
                for N in self.N_cluster_list:
                    if hardest_subjet_z_observable.endswith(f'r{r}_N{N}_q'):
                        # Plot distributions
                        if self.subjet_basis == 'exclusive':
                            plt.xlabel(f'Pythia, hardest z distr., {self.subjet_basis} clust., {self.Clustering_Alg}, N={N}', fontsize=10)
                        if self.subjet_basis == 'inclusive':
                            plt.xlabel(f'Pythia, hardest z distr., {self.subjet_basis} clust., {self.Clustering_Alg}, r={r}', fontsize=10)
                        max = np.amax(mult_result)*1.25
                        bins = np.arange(0., 1, 0.04)
                        if self.dataset_type == 'Zjet':
                            plt.hist(mult_result,
                                    bins,
                                    histtype='step',
                                    density=True,
                                    label = 'Z',
                                    linewidth=2,
                                    linestyle='-',
                                    alpha=0.5)
                        else:
                            plt.hist(mult_result,
                                    bins,
                                    histtype='step',
                                    density=True,
                                    label = 'q',
                                    linewidth=2,
                                    linestyle='-',
                                    alpha=0.5)
                    elif hardest_subjet_z_observable.endswith(f'r{r}_N{N}_g'):
                        if self.dataset_type == 'Zjet':
                            plt.hist(mult_result,
                                    bins,
                                    histtype='step',
                                    density=True,
                                    label = 'QCD',
                                    linewidth=2,
                                    linestyle='-',
                                    alpha=0.5)
                        else:
                            plt.hist(mult_result,
                                    bins,
                                    histtype='step',
                                    density=True,
                                    label = 'g',
                                    linewidth=2,
                                    linestyle='-',
                                    alpha=0.5)
                        plt.legend(loc='best', fontsize=14, frameon=True)
                        plt.ylabel('\\textit{Density}', fontsize=20)
                        plt.tight_layout()
                        plt.savefig(os.path.join(self.output_dir, f'hardest z distribution r={r}, N={N}.pdf'))
                        plt.close()  



        for subjet_z_observable in self.output_numpy['subjet_z'].keys():

            mult_result = self.output_numpy['subjet_z'][subjet_z_observable]
            mult_observable_shape = mult_result.shape
            bin_size = 0.02
            for r in self.r_list:
                for N in self.N_cluster_list:
                    if subjet_z_observable.endswith(f'r{r}_N{N}_q'):
                        weights_q= np.ones_like(mult_result)/float(len(mult_result))/bin_size * 26.7 # To normalize the curve s.t. it integrates to <n_q>=33.6 for pt=500

                        # Plot distributions
                        if self.subjet_basis == 'exclusive':
                            plt.xlabel(f'z distribution', fontsize=16 )
                        if self.subjet_basis == 'inclusive':
                            plt.xlabel(f'z distribution', fontsize=16)
                        bins = np.arange(0., 1, bin_size)
                        if self.dataset_type == 'Zjet':
                            plt.hist(mult_result,
                                    bins, 
                                    histtype='step',
                                    density=True,
                                    label = 'Z',
                                    linewidth=2,
                                    linestyle='-',
                                    alpha=0.5)
                        else:
                            plt.hist(mult_result,
                                    bins, weights= weights_q,
                                    histtype='step',
                                    density=True,
                                    label = 'q',
                                    linewidth=2,
                                    linestyle='-',
                                    alpha=0.5)
                    elif subjet_z_observable.endswith(f'r{r}_N{N}_g'):
                        weights_g= np.ones_like(mult_result)/float(len(mult_result))/bin_size * 29.8 # To normalize the curve s.t. it integrates to <n_g>=56 for pt=500

                        if self.dataset_type == 'Zjet':
                            plt.hist(mult_result,
                                    bins,
                                    histtype='step',
                                    label = 'QCD',
                                    linewidth=2,
                                    linestyle='-',
                                    alpha=0.5)
                        else:
                            plt.hist(mult_result,
                                    bins, weights= weights_g,
                                    histtype='step',
                                    label = 'g',
                                    linewidth=2,
                                    linestyle='-',
                                    alpha=0.5)
                        if self.subjet_basis == 'inclusive':
                            plt.legend(loc='best', fontsize=22, frameon=True, shadow = True, edgecolor="black", title = r"$r=$"f"{r}", title_fontsize = 22)
                        else:
                            plt.legend(loc='best', fontsize=22, frameon=True, shadow = True, edgecolor="black", title = r"$N=$"f"{N}", title_fontsize = 22)

                        plt.yticks(fontsize=19)
                        plt.xticks(fontsize=19)
                        plt.ylabel(r"$\frac{1}{\sigma} \ d\sigma / dz$", fontsize=28)
                        plt.xlabel(r"$z$",fontsize=28)
                        plt.yscale('log')
                        plt.xlim([0,1])
                        plt.ylim([0.005, 2000])
                        plt.tight_layout()
                        plt.savefig(os.path.join(self.output_dir, f'z distribution of subjets r={r}, N={N}.pdf'))
                        plt.close()


        for qa_observable in self.output_numpy['qa'].keys():
            
            qa_result = self.output_numpy['qa'][qa_observable]
            qa_observable_shape = qa_result.shape
            if qa_observable_shape[0] == 0:
                continue

            # Plot distributions
            if qa_observable == 'jet_mass':
                plt.xlabel(rf'{qa_observable}', fontsize=14)
                max = np.amax(qa_result)*1.2
                bins = np.linspace(0, max, 80)
                plt.hist(qa_result,
                        bins,
                        histtype='step',
                        density=True,
                        label = 'q or g',
                        linewidth=2,
                        linestyle='-',
                        alpha=0.5)
                plt.legend(loc='best', fontsize=14, frameon=False)
            
                plt.tight_layout()
                plt.savefig(os.path.join(self.output_dir, f'{qa_observable}.pdf'))
                plt.close()  
            else:
                plt.xlabel(rf'{qa_observable}', fontsize=14)
                max = np.amax(qa_result)*1.2
                bins = np.linspace(0, max, 20)
                plt.hist(qa_result,
                        bins,
                        histtype='step',
                        density=True,
                        label = 'q or g',
                        linewidth=2,
                        linestyle='-',
                        alpha=0.5)
                plt.legend(loc='best', fontsize=14, frameon=False)
                
                plt.tight_layout()
                plt.savefig(os.path.join(self.output_dir, f'{qa_observable}.pdf'))
                plt.close()   
                                    
    #---------------------------------------------------------------
    # Transform particles to fastjet::PseudoJets
    #---------------------------------------------------------------
    def get_fjparticles(self, df_particles_grouped):

        # If we load Mateusz's dataset: fjext.vectorize_pt_eta_phi_m(df_particles_grouped['pt'].values, df_particles_grouped['y'].values, df_particles_grouped['phi'].values, df_particles_grouped['m'].values) 
        # If we load Jesse's dataset:   fjext.vectorize_pt_eta_phi(df_particles_grouped['pt'].values, df_particles_grouped['y'].values, df_particles_grouped['phi'].values, user_index_offset) 
        user_index_offset = 0
        return fjext.vectorize_pt_eta_phi_m(df_particles_grouped['pt'].values,
                                          df_particles_grouped['y'].values,
                                          df_particles_grouped['phi'].values,
                                          df_particles_grouped['m'].values) 

##################################################################
if __name__ == '__main__':

    # Define arguments
    parser = argparse.ArgumentParser(description='Process qg')
    parser.add_argument('-c', '--configFile', action='store',
                        type=str, metavar='configFile',
                        default='./config/qg.yaml',
                        help='Path of config file for analysis')
    parser.add_argument('-o', '--outputDir', action='store',
                        type=str, metavar='outputDir',
                        default='./TestOutput',
                        help='Output directory for output to be written to')

    # Parse the arguments
    args = parser.parse_args()

    print('Configuring...')
    print('configFile: \'{0}\''.format(args.configFile))
    print('ouputDir: \'{0}\"'.format(args.outputDir))

    # If invalid configFile is given, exit
    if not os.path.exists(args.configFile):
        print('File \"{0}\" does not exist! Exiting!'.format(args.configFile))
        sys.exit(0)

    analysis = ProcessQG(config_file=args.configFile, output_dir=args.outputDir)
    analysis.process_qg()